{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccacc035-c9e1-4565-bc4d-1da870b4c458",
   "metadata": {},
   "source": [
    "Simple Linear Regression example to predict the first year college grades of students from their high school SAT and GPA scores\n",
    "\n",
    "__Prodigy University__ is seeking to enhance its enrollment process. They plan to do so by implementing a predictive analytics model aimed at identifying prospective students who demonstrate a high potential for academic success. \n",
    "\n",
    "__The goal is to develop a predictive model that can accurately forecast the first-year college GPA of applicants based on their SAT scores and high school scores. This model is intended to serve as a strategic tool for the admissions office, enabling them to efficiently shortlist candidates who not only meet the academic standards of the university but are also likely to thrive in their chosen fields of study.__ By doing so, the university aspires to optimize its student selection process, improve academic outcomes, and foster an environment of excellence and high achievement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241b3dc-9c04-4b48-af8d-a621a387eb2e",
   "metadata": {},
   "source": [
    " # 1) Load The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7cadca-fc4c-466c-995b-5f2384a384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12144e31-9019-44f8-b450-4ed31ce3b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Notebooks/Prodigy University Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd5492a-d3c1-467f-b86a-3ba23311a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   sat_sum  1000 non-null   int64  \n",
      " 1   hs_gpa   1000 non-null   float64\n",
      " 2   fy_gpa   1000 non-null   float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b825e5-e51b-4864-aaa0-640163173867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_sum</th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>fy_gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sat_sum  hs_gpa  fy_gpa\n",
       "0      508    3.40    3.18\n",
       "1      488    4.00    3.33\n",
       "2      464    3.75    3.25\n",
       "3      380    3.75    2.42\n",
       "4      428    4.00    2.63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37106215-2a3b-4e77-9444-8166b7e70f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat_sum</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>413.31600</td>\n",
       "      <td>57.149472</td>\n",
       "      <td>212.0</td>\n",
       "      <td>372.00</td>\n",
       "      <td>412.000</td>\n",
       "      <td>452.00</td>\n",
       "      <td>576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_gpa</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.19810</td>\n",
       "      <td>0.541647</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.200</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fy_gpa</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.46795</td>\n",
       "      <td>0.740805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.465</td>\n",
       "      <td>3.02</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std    min     25%      50%     75%    max\n",
       "sat_sum  1000.0  413.31600  57.149472  212.0  372.00  412.000  452.00  576.0\n",
       "hs_gpa   1000.0    3.19810   0.541647    1.8    2.80    3.200    3.70    4.5\n",
       "fy_gpa   1000.0    2.46795   0.740805    0.0    1.98    2.465    3.02    4.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "473344a0-95da-47e9-b875-c7235ec13bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_sum</th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>fy_gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat_sum</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.430788</td>\n",
       "      <td>0.460281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_gpa</th>\n",
       "      <td>0.430788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fy_gpa</th>\n",
       "      <td>0.460281</td>\n",
       "      <td>0.543353</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sat_sum    hs_gpa    fy_gpa\n",
       "sat_sum  1.000000  0.430788  0.460281\n",
       "hs_gpa   0.430788  1.000000  0.543353\n",
       "fy_gpa   0.460281  0.543353  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc86b63-13fc-4459-ac95-97d043122b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7070f7a-4bfd-422d-a055-12e1c4bd4e71",
   "metadata": {},
   "source": [
    "# 2)Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecaf952f-4ac9-4fb6-b83f-5f779106f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data into numpy\n",
    "x=data[['sat_sum','hs_gpa']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4ba5b2-6226-4d59-aea2-27cc425c4ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bdfe8d8-fea1-4d9c-9817-7a6ab7e99585",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['fy_gpa'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4be4b92-5430-4bc8-8947-091ee37da172",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(-1,1) #because now it will convert in 1 column and 1000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dbc7a4d-c1e1-4192-b906-6939dbcdc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05e456a9-57b3-40f3-a7f0-3f5de13f742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9272b436-cfdd-4043-8e3e-f0299e532eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e62b474b-af17-4150-bc25-652a6c434b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a8c5e16-c67a-49fd-85fc-8573b9db032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6641e5f-d832-4bb0-9b2f-f47b0233b047",
   "metadata": {},
   "source": [
    "# Revision \n",
    "import data ->ceate data frame -> analysis of data --> start preprocessing (preparing the x ,y set ) ---> data split --> apply standarization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3bc9e6-c8a3-4933-ba7f-3c824901be90",
   "metadata": {},
   "source": [
    "# 3) Building model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0036b8ae-7a3e-42ea-933b-d762e263e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6e77460-b43e-49c9-bf53-61793003054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy dataset into tensor\n",
    "X_train=torch.tensor(X_train,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a6514f4-dc1e-42c8-b4a6-ab2721fcfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=torch.tensor(X_test,dtype=torch.float32)\n",
    "y_test=torch.tensor(y_test,dtype=torch.float32)\n",
    "y_train=torch.tensor(y_train,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc1b1d58-3dfc-474a-876d-fad524f7837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fe28db8c-a3a9-4d6a-a015-f1ca8c9a0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building model with 2 neurons\n",
    "model= nn.Sequential(nn.Linear(2,2),   # 2 inputs with 2 neurons\n",
    "                    nn.ReLU(),       #applying non-linarity \n",
    "                    nn.Linear(2,1))     #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdfddbb9-7471-48bc-a1cc-fb8a6723c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65347468-bd18-4aa4-b6b3-b738c7e0858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3882],\n",
       "        [0.1778],\n",
       "        [0.2123],\n",
       "        [0.3663],\n",
       "        [0.5508]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e6fd2-47ed-426a-98b1-b1595ade17df",
   "metadata": {},
   "source": [
    "# 4) Loss calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d2bc346-6700-45a5-997e-5ea4b027a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5aceb99d-4010-48d7-b3cd-86c1f7d49adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8211, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculating loss\n",
    "criterion=MSELoss()\n",
    "loss = criterion(y_pred,y_test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c8f65a2-bb17-4f02-97bf-3c86f2402724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3882],\n",
       "        [0.1778],\n",
       "        [0.2123],\n",
       "        [0.3663],\n",
       "        [0.5508]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54cf2949-c96c-4577-b9be-d5368f4b7dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5400],\n",
       "        [2.9800],\n",
       "        [1.2400],\n",
       "        [1.1300],\n",
       "        [2.3700]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f103192f-aaaf-4cac-bef0-9acef6dd02e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6530, -0.2078],\n",
       "        [ 0.5196,  0.1161]], requires_grad=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bba36f50-e798-40e9-8286-c9287067f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1438, 0.3741]], requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512305a-717d-4f0d-b957-ef0983a87210",
   "metadata": {},
   "source": [
    "# 5) Optimaization \n",
    "updating wieghts through backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe0f17-f80b-4529-93f0-a8161aaf120a",
   "metadata": {},
   "source": [
    "# a) By Normal way\n",
    "only single time will be update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5cd8c215-a4b9-45ef-a886-5b446bf928d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "484ac719-a216-4252-a0d4-421e0b9e0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f06a52f-5974-40ec-b787-e99c54a73739",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #compute gradient for each parameter \n",
    "optimizer.step() #update parameter by above gradient and l.rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9db37ee2-3fb9-4284-9108-34882ed26321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6531, -0.2077],\n",
       "        [ 0.5201,  0.1166]], requires_grad=True)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2cfbb941-1622-4872-86bc-489e1cb1c1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1462, 0.3761]], requires_grad=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf58f6c-a8d2-411c-aacc-5f8ce290c3a3",
   "metadata": {},
   "source": [
    "# Again prepare model for another various optimization techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4ef5f756-c26e-410c-9aa9-8a5734888525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "#for efficently managing sets and making batches too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "37d8fea6-9cd7-44fb-be8d-82f7e02b14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=TensorDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f3a2d72-1448-4e69-a8f2-d089c4e9b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60249515-16fb-4dba-8122-c4a5f6bc4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without training :\n",
      "Train loss : 8.6018, Test Loss : 8.8973\n"
     ]
    }
   ],
   "source": [
    "# performance on train and test sets before apply optimization\n",
    "train_loss=criterion(model(X_train),y_train)\n",
    "test_loss=criterion(model(X_test),y_test)\n",
    "print(f'without training :\\nTrain loss : {train_loss:.4f}, Test Loss : {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b59ac41f-a976-4c76-8cc5-9e71957356b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4544],\n",
       "        [-0.6725],\n",
       "        [-0.6681],\n",
       "        [-0.2929],\n",
       "        [-0.3914]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at predictions\n",
    "model(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d53c1-1587-4834-8730-b4c562c6253e",
   "metadata": {},
   "source": [
    "# b) Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56d943f1-d917-45fe-8226-f1613a15c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1: train loss :0.6405 , test loss :0.7196\n",
      "Epoch :2: train loss :0.5503 , test loss :0.6121\n",
      "Epoch :3: train loss :0.5049 , test loss :0.5619\n",
      "Epoch :4: train loss :0.4668 , test loss :0.5221\n",
      "Epoch :5: train loss :0.4353 , test loss :0.4912\n",
      "Epoch :6: train loss :0.4104 , test loss :0.4646\n",
      "Epoch :7: train loss :0.3932 , test loss :0.4436\n",
      "Epoch :8: train loss :0.3775 , test loss :0.4297\n",
      "Epoch :9: train loss :0.3673 , test loss :0.4216\n",
      "Epoch :10: train loss :0.3609 , test loss :0.4131\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=1,shuffle=True) #in SGD after every row back propagation will happen so batch size 1. \n",
    "#Execute the training loop\n",
    "for epoch in range(10):\n",
    "    for x,y in train_loader:\n",
    "        #Forward pass\n",
    "        pred=model(x)\n",
    "        loss=criterion(pred,y)\n",
    "\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad() #to reset optimizer\n",
    "        loss.backward() #calculate gradient and store it for every parameter\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss=criterion(model(X_train),y_train).item() #to convert loss into python number\n",
    "    test_loss=criterion(model(X_test),y_test).item()\n",
    "    print(f'Epoch :{epoch+1}: train loss :{train_loss:.4f} , test loss :{test_loss:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7fa72bdc-8059-4cec-95d8-6f2bfdea745f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3774],\n",
       "        [2.0693],\n",
       "        [2.0120],\n",
       "        [2.7303],\n",
       "        [2.4329]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking prediction \n",
    "model(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb175f5-a980-4754-b92d-7aa82a19a16c",
   "metadata": {},
   "source": [
    "# b) Batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "321101ec-1197-4b8a-b47e-a7f0720debb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again create model and optimaizer\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "facee3fe-f814-40c0-bdd4-aa95a46085ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :100 :- train loss :4.0618, test loss:4.2772\n",
      "Epoch :200 :- train loss :2.3810, test loss:2.5525\n",
      "Epoch :300 :- train loss :1.4857, test loss:1.6245\n",
      "Epoch :400 :- train loss :1.0141, test loss:1.1289\n",
      "Epoch :500 :- train loss :0.7670, test loss:0.8644\n",
      "Epoch :600 :- train loss :0.6368, test loss:0.7216\n",
      "Epoch :700 :- train loss :0.5666, test loss:0.6423\n",
      "Epoch :800 :- train loss :0.5270, test loss:0.5961\n",
      "Epoch :900 :- train loss :0.5028, test loss:0.5673\n",
      "Epoch :1000 :- train loss :0.4867, test loss:0.5478\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=800,shuffle=True)\n",
    "for epoch in range(1000): #we need to increass no. of epoch for effectice training.\n",
    "    for x,y in train_loader:\n",
    "        #forward pass\n",
    "        pred=model(x)\n",
    "        loss=criterion(pred,y)\n",
    "\n",
    "        #Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1)%100==0:\n",
    "        train_loss=criterion(model(X_train),y_train)\n",
    "        test_loss=criterion(model(X_test),y_test)\n",
    "        print(f'Epoch :{epoch+1} :- train loss :{train_loss:.4f}, test loss:{test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd9f9ddc-c7f1-469b-b025-e2ad06bf63eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3577],\n",
       "        [2.3047],\n",
       "        [2.2813],\n",
       "        [2.4405],\n",
       "        [2.3584]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking prediction \n",
    "model(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f3f7c-467f-4f78-a25e-01033c081ee9",
   "metadata": {},
   "source": [
    " you can see how much epoch we needed to get better result in batch g.d. technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987c1f2-33cd-428d-bbce-35d28506d21e",
   "metadata": {},
   "source": [
    "# c) Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "61bb1887-5d28-4ed8-86bd-62370422f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again reset model and optimaizer\n",
    "#again create model and optimaizer\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "750d63d0-9c9f-4099-9f80-080681c5ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :100 :- train loss :0.4972, test loss:0.5579\n",
      "Epoch :200 :- train loss :0.4459, test loss:0.5002\n",
      "Epoch :300 :- train loss :0.4119, test loss:0.4651\n",
      "Epoch :400 :- train loss :0.3892, test loss:0.4419\n",
      "Epoch :500 :- train loss :0.3746, test loss:0.4274\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "for epoch in range(500):\n",
    "      for x,y in train_loader:\n",
    "        #forward pass\n",
    "        pred=model(x)\n",
    "        loss=criterion(pred,y)\n",
    "\n",
    "        #Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      if (epoch+1)%100==0:\n",
    "        train_loss=criterion(model(X_train),y_train)\n",
    "        test_loss=criterion(model(X_test),y_test)\n",
    "        print(f'Epoch :{epoch+1} :- train loss :{train_loss:.4f}, test loss:{test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "509a1ffe-3497-4270-88ed-7f2088d49595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4191],\n",
       "        [2.0765],\n",
       "        [2.0609],\n",
       "        [2.6672],\n",
       "        [2.4894]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440f547-70f9-44ac-982d-4cd6b15dc78b",
   "metadata": {},
   "source": [
    "# d) Common Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f5aae-21c6-4414-8bbf-639ee762bf44",
   "metadata": {},
   "source": [
    "# i) Gradient Descent with Momentum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4da3889c-ea08-4f1a-aa02-ad6e50eb15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again need to rebuild our model \n",
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e79f5da7-d644-4631-adfe-985e03482c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :100 ==> train loss :0.3419,test loss :0.4006\n",
      "epoch :200 ==> train loss :0.3415,test loss :0.4009\n",
      "epoch :300 ==> train loss :0.3412,test loss :0.4001\n",
      "epoch :400 ==> train loss :0.3410,test loss :0.4006\n",
      "epoch :500 ==> train loss :0.3407,test loss :0.4003\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "for epoch in range(500):\n",
    "    for x,y in train_loader:\n",
    "        pred=model(x)\n",
    "        loss=criterion(pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1)%100==0 :\n",
    "        train_loss=criterion(model(X_train),y_train)\n",
    "        test_loss=criterion(model(X_test),y_test)\n",
    "        print(f'epoch :{epoch+1} ==> train loss :{train_loss:.4f},test loss :{test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "06bc142b-8e4a-4e2a-9126-259afd84ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3091],\n",
       "        [1.9076],\n",
       "        [1.8717],\n",
       "        [2.7633],\n",
       "        [2.3899]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d9ab3695-94d9-4f55-99ce-c7cb66249806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5400],\n",
       "        [2.9800],\n",
       "        [1.2400],\n",
       "        [1.1300],\n",
       "        [2.3700]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a98b6-31d4-4576-af0c-118e1aff58a0",
   "metadata": {},
   "source": [
    "# ii)Nesterov Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b668f17-ee58-4cd5-a699-a477413c6cc8",
   "metadata": {},
   "source": [
    "#In this , gradient will calculate with consideration of future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d284f72a-95f5-4ff8-b3a8-d6f1bc25723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again build the model\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9,nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "73d61865-e5a5-4bd3-98c4-f63bd7d2de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :100 ==> train loss :0.3472, test loss :0.4042\n",
      "epoch :200 ==> train loss :0.3432, test loss :0.4043\n",
      "epoch :300 ==> train loss :0.3422, test loss :0.4040\n",
      "epoch :400 ==> train loss :0.3416, test loss :0.4032\n",
      "epoch :500 ==> train loss :0.3411, test loss :0.4026\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,shuffle=True,batch_size=64)\n",
    "for epoch in range(500):\n",
    "    for x,y in train_loader:\n",
    "        pred=model(x)\n",
    "        loss=criterion(pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1)%100==0:\n",
    "        train_loss=criterion(model(X_train),y_train)\n",
    "        test_loss=criterion(model(X_test),y_test)\n",
    "        print(f'epoch :{epoch+1} ==> train loss :{train_loss:.4f}, test loss :{test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b756f-0d15-40d3-b4ac-d6eb1af4dfc1",
   "metadata": {},
   "source": [
    "# iii) AdaGrad => Adaptive Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "69cfb994-47e6-453f-96a2-9a810e1331c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again build the model\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "optimizer=optim.Adagrad(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e92372cd-b20c-4ba4-9a35-d3bdc27c8614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 4.6476, Test Loss: 4.8736\n",
      "Epoch 100: Train Loss: 2.9867, Test Loss: 3.1752\n",
      "Epoch 150: Train Loss: 2.0172, Test Loss: 2.1784\n",
      "Epoch 200: Train Loss: 1.4195, Test Loss: 1.5590\n",
      "Epoch 250: Train Loss: 1.0435, Test Loss: 1.1655\n",
      "Epoch 300: Train Loss: 0.8055, Test Loss: 0.9136\n",
      "Epoch 350: Train Loss: 0.6538, Test Loss: 0.7506\n",
      "Epoch 400: Train Loss: 0.5562, Test Loss: 0.6440\n",
      "Epoch 450: Train Loss: 0.4930, Test Loss: 0.5736\n",
      "Epoch 500: Train Loss: 0.4517, Test Loss: 0.5266\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_data,shuffle=True,batch_size=64)\n",
    "# Execute the training loop\n",
    "for epoch in range(500): # increasing the epochs for effective training\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0: # printing after every 100 epochs\n",
    "        train_loss = criterion(model(X_train), y_train).item()\n",
    "        # print(epoch,': ', train_loss)\n",
    "        test_loss = criterion(model(X_test), y_test).item()\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c272fb-1be6-40d9-abdf-30bfb448f283",
   "metadata": {},
   "source": [
    "Adagrad has given us a high intial loss but the final loss values of VALUE on the train data and VALUE on the test data. Next let's try RMSProp!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb705c1-a06c-40b2-a47e-37fad66081c5",
   "metadata": {},
   "source": [
    "# iv) RMS Prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731119d9-5a92-4660-a56e-30009a66b635",
   "metadata": {},
   "source": [
    "Just like we did with Adagrad earlier, here we need to use optim.RMSprop to intitialize the model with RMSProp. Even though we are going to use the default parameters, RMSprop also has parameters such as, learning rate, momentum etc,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "74f41968-2eae-4c4a-98e0-b5b5e9610c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialising model weights\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "optimizer = optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "83434f1e-d475-4f3b-8d7d-4cb277028758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 0.3443, Test Loss: 0.4053\n",
      "Epoch 100: Train Loss: 0.3416, Test Loss: 0.4064\n",
      "Epoch 150: Train Loss: 0.3396, Test Loss: 0.3991\n",
      "Epoch 200: Train Loss: 0.3415, Test Loss: 0.3987\n",
      "Epoch 250: Train Loss: 0.3418, Test Loss: 0.3992\n",
      "Epoch 300: Train Loss: 0.3400, Test Loss: 0.3987\n",
      "Epoch 350: Train Loss: 0.3392, Test Loss: 0.3985\n",
      "Epoch 400: Train Loss: 0.3396, Test Loss: 0.3985\n",
      "Epoch 450: Train Loss: 0.3390, Test Loss: 0.3990\n",
      "Epoch 500: Train Loss: 0.3384, Test Loss: 0.4006\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size= 64, shuffle=True) #800 is the number of samples in train set\n",
    "# Execute the training loop\n",
    "for epoch in range(500): # increasing the epochs for effective training\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0: # printing after every 100 epochs\n",
    "        train_loss = criterion(model(X_train), y_train).item()\n",
    "        # print(epoch,': ', train_loss)\n",
    "        test_loss = criterion(model(X_test), y_test).item()\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286f357-ab65-4585-8330-878d9467db93",
   "metadata": {},
   "source": [
    "With RMSProp we have clearly achieved our lowest loss values so far. We have got final loss values of VALUE on the train data and VALUE on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b0917-d32c-49e0-9020-3fff8754d1b8",
   "metadata": {},
   "source": [
    "# v) Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "10da343f-cc6f-4550-8dd7-6290b8bfdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialising model weights\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6b63e25e-5e56-4fb7-9621-8a8c1d483a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 2.6235, Test Loss: 2.8095\n",
      "Epoch 100: Train Loss: 0.7141, Test Loss: 0.8228\n",
      "Epoch 150: Train Loss: 0.3625, Test Loss: 0.4272\n",
      "Epoch 200: Train Loss: 0.3473, Test Loss: 0.4035\n",
      "Epoch 250: Train Loss: 0.3460, Test Loss: 0.4022\n",
      "Epoch 300: Train Loss: 0.3449, Test Loss: 0.4016\n",
      "Epoch 350: Train Loss: 0.3438, Test Loss: 0.4012\n",
      "Epoch 400: Train Loss: 0.3428, Test Loss: 0.4009\n",
      "Epoch 450: Train Loss: 0.3418, Test Loss: 0.4004\n",
      "Epoch 500: Train Loss: 0.3409, Test Loss: 0.3998\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size= 64, shuffle=True) #800 is the number of samples in train set\n",
    "# Execute the training loop\n",
    "for epoch in range(500): # increasing the epochs for effective training\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0: # printing after every 100 epochs\n",
    "        train_loss = criterion(model(X_train), y_train).item()\n",
    "        # print(epoch,': ', train_loss)\n",
    "        test_loss = criterion(model(X_test), y_test).item()\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b79ccf-eb45-4649-b734-a74b4b6e9525",
   "metadata": {},
   "source": [
    "The Adam optimizer too has given us good overall performance. As per our observations, RMSProp is the best of the lot for optimizing the loss in our case. You've now explored a variety of optimization algorithms, each with unique approaches to navigating the complex landscape of neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e81ef-9882-466e-a553-a202bff3d152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
